# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y1jRJvzhlUjdd66vnUOBj57YzwXHYc1s
"""

diff --git a/01app.py b/01app.py
index 182114f5cdd1f4db1b979a53f601f0c86578a9af..17b6c0c3f9ae0b0e11f8716b0a0a301e589c6862 100644
--- a/01app.py
+++ b/01app.py
@@ -29,120 +29,211 @@ TRADING_DAYS = 252
 RISK_FREE_RATE = 0.01  # ç„¡é¢¨éšªåˆ©ç‡

# app.py
# -*- coding: utf-8 -*-

import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
from scipy.stats import spearmanr
import plotly.graph_objects as go
import altair as alt


 # ===============================
 # ETF Universe & å¸‚å ´åŸºæº–
 # ===============================
 ETF_LIST = {
     "0050.TW": "è‚¡ç¥¨å‹",
     "006208.TW": "è‚¡ç¥¨å‹",
     "00692.TW": "è‚¡ç¥¨å‹",
     "00757.TW": "è‚¡ç¥¨å‹",
     "0056.TW": "é«˜è‚¡æ¯å‹",
     "00878.TW": "é«˜è‚¡æ¯å‹",
     "00919.TW": "é«˜è‚¡æ¯å‹",
 }
 MARKET_BENCHMARK = "0050.TW"
 
 # ===============================
 # Sidebarï¼šä½¿ç”¨è€…è¨­å®š
 # ===============================
 st.sidebar.header("ğŸ‘¤ æŠ•è³‡äººé¢¨éšªè¨­å®š")
 age = st.sidebar.slider("å¹´é½¡", 20, 80, 35)
 horizon = st.sidebar.slider("æŠ•è³‡å¹´é™ï¼ˆå¹´ï¼‰", 1, 30, 10)
 loss_tol = st.sidebar.slider("å¯æ¥å—æœ€å¤§æå¤± (%)", 0, 50, 20)
 reaction = st.sidebar.radio("å¸‚å ´ä¸‹è·Œ 20% æ™‚", ["è³£å‡º", "è§€æœ›", "åŠ ç¢¼"])
 
-theta = ((80 - age)/60 + horizon/30 + loss_tol/50 + {"è³£å‡º":0,"è§€æœ›":0.5,"åŠ ç¢¼":1}[reaction])/4
-theta = np.clip(theta, 0, 1)
-st.sidebar.metric("Î¸ï¼ˆé¢¨éšªåå¥½æŒ‡æ•¸ï¼‰", round(theta, 2))
+st.sidebar.header("ğŸ‘¤ é¢¨éšªåå¥½è©•ä¼°ï¼ˆå­¸è¡“æ¨™æº–ç‰ˆï¼‰")
+evaluation_method = st.sidebar.radio(
+    "é¸æ“‡è©•ä¼°æ–¹æ³•",
+    ["æ¨™æº–å•å·æ³•ï¼ˆSCFï¼‰", "æ•ˆç”¨å‡½æ•¸æ³•ï¼ˆCRRAï¼‰", "æ··åˆæ³•ï¼ˆæ¨è–¦ï¼‰"]
+)
+
+def compute_theta_scf(age, horizon, loss_tol, reaction):
+    return np.clip(
+        ((80 - age) / 60 + horizon / 30 + loss_tol / 50 + {"è³£å‡º": 0, "è§€æœ›": 0.5, "åŠ ç¢¼": 1}[reaction]) / 4,
+        0,
+        1,
+    )
+
+def compute_theta_crra():
+    gamma = st.sidebar.slider("CRRA é¢¨éšªå­æƒ¡ä¿‚æ•¸ Î³", 0.5, 10.0, 3.0, 0.5)
+    risky_ratio = st.sidebar.slider("é¢¨éšªè³‡ç”¢é…ç½®æ¯”é‡ (%)", 0, 100, 50)
+    # Î³ è¶Šé«˜é¢¨éšªåå¥½è¶Šä½ï¼›é¢¨éšªè³‡ç”¢é…ç½®è¶Šé«˜é¢¨éšªåå¥½è¶Šé«˜
+    gamma_score = np.clip((10.0 - gamma) / 9.5, 0, 1)
+    alloc_score = np.clip(risky_ratio / 100, 0, 1)
+    return np.clip(0.6 * alloc_score + 0.4 * gamma_score, 0, 1)
+
+theta_scf = compute_theta_scf(age, horizon, loss_tol, reaction)
+
+if evaluation_method == "æ¨™æº–å•å·æ³•ï¼ˆSCFï¼‰":
+    theta = theta_scf
+    st.sidebar.metric("Î¸ï¼ˆSCFï¼‰", round(theta, 3))
+elif evaluation_method == "æ•ˆç”¨å‡½æ•¸æ³•ï¼ˆCRRAï¼‰":
+    theta = compute_theta_crra()
+    st.sidebar.metric("Î¸ï¼ˆCRRAï¼‰", round(theta, 3))
+else:
+    theta_crra = compute_theta_crra()
+    theta = np.clip(0.6 * theta_scf + 0.4 * theta_crra, 0, 1)
+    st.sidebar.markdown("---")
+    st.sidebar.subheader("ğŸ“Š æ··åˆè©•ä¼°çµæœ")
+    st.sidebar.metric("Î¸ï¼ˆSCFï¼‰", f"{theta_scf:.3f}")
+    st.sidebar.metric("Î¸ï¼ˆCRRAï¼‰", f"{theta_crra:.3f}")
+    st.sidebar.metric("Î¸ï¼ˆæ··åˆï¼‰", f"{theta:.3f}", delta=f"{theta - theta_scf:.3f} vs SCF")
 
 def alpha_from_theta(theta, alpha_min=0.1, alpha_max=0.7):
     return alpha_min + (alpha_max - alpha_min) * theta
 
 ALPHA_MODEL = alpha_from_theta(theta)
 
 st.sidebar.header("âš–ï¸ ç¶œåˆåˆ†æ•¸æ¬Šé‡")
 st.sidebar.write(
     f"ğŸ“Œ HotIndex æ¬Šé‡ (å…§ç”Ÿ Î±ï¼Œä¾ Î¸ è¨ˆç®—): {ALPHA_MODEL:.2f}\n"
     f"ğŸ“Œ å€‹äººåŒ–åˆ†æ•¸æ¬Šé‡: {1-ALPHA_MODEL:.2f}\n"
     "(æ‰‹å‹• slider Î± åƒ…ä¾›åƒè€ƒï¼Œä¸å½±éŸ¿æ’åº)"
 )
 st.sidebar.slider("HotIndex æ¬Šé‡ï¼ˆåƒ…ä¾›åƒè€ƒï¼‰", 0.0, 1.0, 0.5, step=0.05)
 
 st.sidebar.header("ğŸ“Š æ’åºé¸æ“‡")
 sort_option = st.sidebar.selectbox("é¸æ“‡æ’åºä¾æ“š", ["Final Score (HotIndex + å€‹äººåŒ–)", "é¢¨éšªé©é…åˆ†æ•¸ï¼ˆä¾ Î¸ï¼‰"])
 
 st.sidebar.header("ğŸ“ˆ Top N ETF é¡¯ç¤º")
 TOP_N = st.sidebar.slider("Top N ETF", 1, len(ETF_LIST), 5)
 
+st.sidebar.header("ğŸ”„ å³æ™‚æ›´æ–°")
+if st.sidebar.button("æ¸…é™¤å¿«å–ä¸¦æ›´æ–°å ±åƒ¹"):
+    st.cache_data.clear()
+    st.sidebar.success("å·²æ¸…é™¤å¿«å–ï¼Œå°‡é‡æ–°æŠ“å–å ±åƒ¹")
+price_source = st.sidebar.selectbox("æœ€æ–°åƒ¹ä¾†æº", ["auto", "fast_info", "1m"], index=0)
+latest_ttl = st.sidebar.slider("æœ€æ–°åƒ¹å¿«å–ç§’æ•¸", 0, 120, 10, step=5)
+st.sidebar.caption("æç¤ºï¼šYahoo è³‡æ–™é€šå¸¸å»¶é²ï¼Œè‹¥éœ€æ›´å³æ™‚è«‹æ”¹ç”¨åˆ¸å•†æˆ–å®˜æ–¹ APIã€‚")
+
 # ===============================
 # æŠ“å–åƒ¹æ ¼è³‡æ–™
 # ===============================
-@st.cache_data(ttl=86400)
-def fetch_all_price_data(etf_list, benchmark, period="1y"):
-    data = {}
-    tickers = list(etf_list.keys()) + [benchmark]
-    for code in set(tickers):
-        try:
-            df = yf.Ticker(code).history(period=period)
-            if not df.empty and len(df) >= 50:
-                data[code] = df
-        except Exception:
-            data[code] = None
-    return data
-
 @st.cache_data(ttl=300)  # 5 åˆ†é˜
 def fetch_all_price_data(etf_list, benchmark, period="1y"):
     data = {}
     tickers = list(etf_list.keys()) + [benchmark]
     for code in set(tickers):
         try:
             df = yf.Ticker(code).history(period=period)
             if not df.empty and len(df) >= 50:
                 data[code] = df
         except Exception:
             data[code] = None
     return data
 
+def fetch_latest_price(code, source="auto"):
+    try:
+        ticker = yf.Ticker(code)
+        if source in ("auto", "fast_info"):
+            fast_info = getattr(ticker, "fast_info", None)
+            if fast_info:
+                for key in ("last_price", "lastPrice", "regularMarketPrice"):
+                    price = fast_info.get(key)
+                    if price:
+                        return float(price)
+            if source == "fast_info":
+                return None
+        df = yf.download(code, period="1d", interval="1m", progress=False)
+        if df is None or df.empty:
+            return None
+        return float(df["Close"].iloc[-1])
+    except Exception:
+        return None
+
+def get_cached_latest_price(code, source, ttl_seconds):
+    if "latest_price_cache" not in st.session_state:
+        st.session_state.latest_price_cache = {}
+    cache = st.session_state.latest_price_cache
+    now = datetime.utcnow().timestamp()
+    if ttl_seconds > 0 and code in cache:
+        cached = cache[code]
+        if now - cached["ts"] <= ttl_seconds:
+            return cached["price"]
+    price = fetch_latest_price(code, source=source)
+    if ttl_seconds > 0:
+        cache[code] = {"price": price, "ts": now}
+    return price
+
 @st.cache_data(ttl=300)  # 5 åˆ†é˜
 def fetch_dividend_info(code):
     try:
         ticker = yf.Ticker(code)
         dividends = ticker.dividends
+        fast_info = getattr(ticker, "fast_info", None)
+        ex_dividend_date = None
+        if fast_info:
+            ex_date = fast_info.get("ex_dividend_date")
+            if ex_date:
+                if isinstance(ex_date, (int, float)):
+                    ex_dividend_date = pd.to_datetime(ex_date, unit="s").date()
+                else:
+                    ex_dividend_date = pd.to_datetime(ex_date).date()
         if dividends is None or dividends.empty:
-            return {"æœ€æ–°é…æ¯æ—¥": None, "æœ€è¿‘ä¸€æ¬¡é…æ¯": 0.0, "TTMé…æ¯": 0.0, "TTMæ®–åˆ©ç‡%": 0.0}
+            last_dividend = 0.0
+            if fast_info:
+                last_dividend = float(fast_info.get("last_dividend_value") or 0.0)
+            return {
+                "æœ€æ–°é…æ¯æ—¥": None,
+                "é™¤æ¬Šæ¯æ—¥": ex_dividend_date,
+                "æœ€è¿‘ä¸€æ¬¡é…æ¯": round(last_dividend, 3),
+                "TTMé…æ¯": 0.0,
+                "TTMæ®–åˆ©ç‡%": 0.0,
+            }
         one_year_ago = pd.Timestamp.today() - pd.DateOffset(years=1)
         ttm_dividends = dividends[dividends.index >= one_year_ago]
         latest_date = dividends.index[-1]
         latest_div = float(dividends.iloc[-1])
         price = ticker.history(period="5d")["Close"].iloc[-1]
         ttm_sum = float(ttm_dividends.sum())
         yield_ttm = (ttm_sum / price) * 100 if price > 0 else 0
-        return {"æœ€æ–°é…æ¯æ—¥": latest_date.date(), "æœ€è¿‘ä¸€æ¬¡é…æ¯": round(latest_div,3),
-                "TTMé…æ¯": round(ttm_sum,3), "TTMæ®–åˆ©ç‡%": round(yield_ttm,2)}
+        return {
+            "æœ€æ–°é…æ¯æ—¥": latest_date.date(),
+            "é™¤æ¬Šæ¯æ—¥": ex_dividend_date,
+            "æœ€è¿‘ä¸€æ¬¡é…æ¯": round(latest_div, 3),
+            "TTMé…æ¯": round(ttm_sum, 3),
+            "TTMæ®–åˆ©ç‡%": round(yield_ttm, 2),
+        }
     except Exception:
-        return {"æœ€æ–°é…æ¯æ—¥": None, "æœ€è¿‘ä¸€æ¬¡é…æ¯": 0.0, "TTMé…æ¯": 0.0, "TTMæ®–åˆ©ç‡%": 0.0}
+        return {
+            "æœ€æ–°é…æ¯æ—¥": None,
+            "é™¤æ¬Šæ¯æ—¥": None,
+            "æœ€è¿‘ä¸€æ¬¡é…æ¯": 0.0,
+            "TTMé…æ¯": 0.0,
+            "TTMæ®–åˆ©ç‡%": 0.0,
+        }
 
 # ===============================
 # æŒ‡æ¨™è¨ˆç®—
 # ===============================
 def calc_metrics(df, market_df):
     r = df["Close"].pct_change().dropna()
     mr = market_df["Close"].pct_change().dropna()
     idx = r.index.intersection(mr.index)
     r, mr = r.loc[idx], mr.loc[idx]
     ann_ret = r.mean() * TRADING_DAYS
     ann_vol = r.std() * np.sqrt(TRADING_DAYS)
     sharpe = (ann_ret - RISK_FREE_RATE) / ann_vol if ann_vol>0 else 0
     beta = np.cov(r, mr)[0,1] / np.var(mr)
     return ann_ret*100, ann_vol*100, sharpe, beta
 
 def compute_hot_index(df, window=20):
     volume_ma = df["Volume"].rolling(window).mean().iloc[-1]
     returns = df["Close"].pct_change()
     volatility = returns.rolling(window).std().iloc[-1]
     flow_proxy = (df["Close"]*df["Volume"]).rolling(window).mean().iloc[-1]
     return {"volume_score": volume_ma, "volatility": volatility, "flow_proxy": flow_proxy}
 
 def robust_zscore(series):
     med = np.median(series)
     mad = np.median(np.abs(series - med))
@@ -154,123 +245,132 @@ def compute_personalized_score(ann_ret, ann_vol, sharpe, beta, theta):
     expected_return = 5 + theta * 20
     acceptable_vol = 10 + theta * 25
     ideal_beta = 0.7 + theta * 0.8
     sharpe_fit = min(sharpe/3,1)
     return_fit = np.clip(1 - abs(ann_ret - expected_return)/expected_return,0,1)
     vol_fit = np.clip(1 - ann_vol/acceptable_vol,0,1)
     beta_fit = np.clip(1 - abs(beta - ideal_beta)/ideal_beta,0,1)
     personal_score = np.mean([sharpe_fit, return_fit, vol_fit, beta_fit])
     return {"personal_score": personal_score, "sharpe_fit":sharpe_fit, "return_fit":return_fit,
             "vol_fit":vol_fit,"beta_fit":beta_fit}
 
 def compute_final_score(hot_index_norm, personal_score, alpha):
     return alpha*hot_index_norm + (1-alpha)*personal_score
 
 # ===============================
 # ä¸»æµç¨‹
 # ===============================
 price_data = fetch_all_price_data(ETF_LIST, MARKET_BENCHMARK)
 market_df = price_data.get(MARKET_BENCHMARK)
 
 rows=[]
 for etf, etf_type in ETF_LIST.items():
     df = price_data.get(etf)
     if df is None or market_df is None:
         continue
+    latest_price = get_cached_latest_price(etf, price_source, latest_ttl)
+    if latest_price is None:
+        latest_price = float(df["Close"].iloc[-1])
     ann_ret, ann_vol, sharpe, beta = calc_metrics(df, market_df)
     comp = compute_personalized_score(ann_ret, ann_vol, sharpe, beta, theta)
     risk_score = comp["vol_fit"]*0.4 + comp["beta_fit"]*0.3 + comp["return_fit"]*0.2 + comp["sharpe_fit"]*0.1
     div_info = fetch_dividend_info(etf)
     hot_metrics = compute_hot_index(df)
     row = {
-        "ETF":etf, "é¡å‹":etf_type, "æœ€æ–°åƒ¹":round(df["Close"].iloc[-1],2),
-        "æœ€æ–°é…æ¯æ—¥": div_info["æœ€æ–°é…æ¯æ—¥"], "æœ€è¿‘ä¸€æ¬¡é…æ¯":div_info["æœ€è¿‘ä¸€æ¬¡é…æ¯"],
+        "ETF":etf, "é¡å‹":etf_type, "æœ€æ–°åƒ¹":round(latest_price,2),
+        "æœ€æ–°é…æ¯æ—¥": div_info["æœ€æ–°é…æ¯æ—¥"],
+        "é™¤æ¬Šæ¯æ—¥": div_info["é™¤æ¬Šæ¯æ—¥"],
+        "æœ€è¿‘ä¸€æ¬¡é…æ¯":div_info["æœ€è¿‘ä¸€æ¬¡é…æ¯"],
         "TTMé…æ¯":div_info["TTMé…æ¯"], "TTMæ®–åˆ©ç‡%":div_info["TTMæ®–åˆ©ç‡%"],
         "Sharpe":round(sharpe,2), "Beta":round(beta,2), "å¹´åŒ–å ±é…¬%":round(ann_ret,2),
         "å¹´åŒ–æ³¢å‹•%":round(ann_vol,2), "å€‹äººåŒ–åˆ†æ•¸":round(comp["personal_score"],3),
         "é¢¨éšªé©é…åˆ†æ•¸":round(risk_score,3),
         "volume_score":hot_metrics["volume_score"], "volatility":hot_metrics["volatility"],
         "flow_proxy":hot_metrics["flow_proxy"],
         "Sharpeé©é…":round(comp["sharpe_fit"],2), "å ±é…¬é©é…":round(comp["return_fit"],2),
         "æ³¢å‹•é©é…":round(comp["vol_fit"],2), "Betaé©é…":round(comp["beta_fit"],2)
     }
     rows.append(row)
 
 df_all = pd.DataFrame(rows)
+if df_all.empty:
+    st.error("ç„¡æ³•å–å¾—å³æ™‚/æ­·å²å ±åƒ¹è³‡æ–™ï¼Œè«‹ç¨å¾Œé‡è©¦æˆ–ä½¿ç”¨æ¸…é™¤å¿«å–æ›´æ–°ã€‚")
+    st.stop()
 df_all["hot_index"] = df_all["volume_score"] + df_all["flow_proxy"] - df_all["volatility"]
 df_all["hot_index_norm"] = robust_zscore(df_all["hot_index"]).fillna(0)
 
 # ===============================
 # Î¸ æ’åº & Top-N è¡¨æ ¼
 # ===============================
 THETA_LIST = [0.0,0.25,0.5,0.75,1.0]
 theta_rankings = {}
 
 for t in THETA_LIST:
     rows_theta=[]
     for etf, etf_type in ETF_LIST.items():
         df = price_data.get(etf)
         if df is None or market_df is None:
             continue
         ann_ret, ann_vol, sharpe, beta = calc_metrics(df, market_df)
         comp = compute_personalized_score(ann_ret, ann_vol, sharpe, beta, t)
         final_score = compute_final_score(
             df_all.loc[df_all["ETF"]==etf, "hot_index_norm"].values[0],
             comp["personal_score"],
             ALPHA_MODEL
         )
         base_row = df_all[df_all["ETF"]==etf].iloc[0]
         row = {"ETF":etf,"é¡å‹":etf_type,"Î¸":t,"æœ€æ–°åƒ¹":base_row["æœ€æ–°åƒ¹"],
-               "æœ€æ–°é…æ¯æ—¥":base_row["æœ€æ–°é…æ¯æ—¥"],"æœ€è¿‘ä¸€æ¬¡é…æ¯":base_row["æœ€è¿‘ä¸€æ¬¡é…æ¯"],
+               "æœ€æ–°é…æ¯æ—¥":base_row["æœ€æ–°é…æ¯æ—¥"],"é™¤æ¬Šæ¯æ—¥":base_row["é™¤æ¬Šæ¯æ—¥"],
+               "æœ€è¿‘ä¸€æ¬¡é…æ¯":base_row["æœ€è¿‘ä¸€æ¬¡é…æ¯"],
                "TTMé…æ¯":base_row["TTMé…æ¯"],"TTMæ®–åˆ©ç‡%":base_row["TTMæ®–åˆ©ç‡%"],
                "final_score":final_score,**comp,"hot_index":base_row["hot_index"]}
         rows_theta.append(row)
     df_theta = pd.DataFrame(rows_theta).sort_values("final_score", ascending=False)
     theta_rankings[t] = df_theta
 
 theta_display_closest = min(THETA_LIST, key=lambda x: abs(x-theta))
 df_ui = theta_rankings[theta_display_closest].head(TOP_N)
 
 # ===============================
 # é›·é”åœ–å°ˆç”¨è³‡æ–™
 # ===============================
 radar_metrics = ["sharpe_fit", "return_fit", "vol_fit", "beta_fit"]
 df_radar = df_ui.copy()
 for col in radar_metrics:
     min_v = df_radar[col].min()
     max_v = df_radar[col].max()
     if max_v > min_v:
         df_radar[col] = (df_radar[col] - min_v) / (max_v - min_v)
     else:
         df_radar[col] = 0.5
 
 # ===============================
 # Top-N è¡¨æ ¼
 # ===============================
 st.subheader(f"ğŸ¯ Top {TOP_N} ETF æ’åºï¼ˆÎ¸={round(theta,2)}, final_scoreï¼‰")
 st.dataframe(
-    df_ui[["ETF","é¡å‹","æœ€æ–°åƒ¹","æœ€æ–°é…æ¯æ—¥","æœ€è¿‘ä¸€æ¬¡é…æ¯",
+    df_ui[["ETF","é¡å‹","æœ€æ–°åƒ¹","æœ€æ–°é…æ¯æ—¥","é™¤æ¬Šæ¯æ—¥","æœ€è¿‘ä¸€æ¬¡é…æ¯",
            "TTMé…æ¯","TTMæ®–åˆ©ç‡%","final_score","personal_score",
            "sharpe_fit","return_fit","vol_fit","beta_fit","hot_index"]],
     use_container_width=True
 )
 
 # ===============================
 # Top-N é›·é”åœ– (Plotly)
 # ===============================
 st.subheader(f"ğŸ•¸ï¸ Top {TOP_N} ETF å¤šæŒ‡æ¨™é›·é”åœ–")
 radar_labels = ["Sharpe", "Return", "Volatility", "Beta"]
 fig = go.Figure()
 for _, row in df_radar.iterrows():
     values = [row[m] for m in radar_metrics]
     values.append(values[0])
     fig.add_trace(go.Scatterpolar(
         r=values,
         theta=radar_labels + [radar_labels[0]],
         fill="toself",
         name=row["ETF"],
         opacity=0.6
     ))
 fig.update_layout(
     polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
     showlegend=True,
     margin=dict(l=40, r=40, t=40, b=60)
